{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dea4fb01",
   "metadata": {},
   "source": [
    "# **Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "555bc376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score,classification_report,mean_squared_error\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985157b3",
   "metadata": {},
   "source": [
    "# **Data Inspecting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a6a09",
   "metadata": {},
   "source": [
    "### Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fc246cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_8692\\1591714977.py:1: DtypeWarning: Columns (0,2,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  info_df = pd.read_csv('Classification_Dataset/info_base_games.csv')\n"
     ]
    }
   ],
   "source": [
    "info_df = pd.read_csv('Classification_Dataset/info_base_games.csv')\n",
    "gamalytic_df = pd.read_csv('Classification_Dataset/ms2_gamalytic_steam_games.csv')\n",
    "dlcs_df = pd.read_csv('Classification_Dataset/dlcs.csv')\n",
    "demos_df = pd.read_csv('Classification_Dataset/demos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d1e06",
   "metadata": {},
   "source": [
    "### Renaming the id columns (so i can easliy merge the columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e62efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.rename(columns={'appid': 'id'}, inplace=True)\n",
    "gamalytic_df.rename(columns={'steamId': 'id'}, inplace=True)\n",
    "dlcs_df.rename(columns={'base_appid': 'id'}, inplace=True)\n",
    "demos_df.rename(columns={'full_game_appid': 'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dbb5c5",
   "metadata": {},
   "source": [
    "### adjusting the id data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2976151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df['id'] = info_df['id'].astype(str)\n",
    "gamalytic_df['id'] = gamalytic_df['id'].astype(str)\n",
    "dlcs_df['id'] = dlcs_df['id'].astype(str)\n",
    "demos_df['id'] = demos_df['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f13bd4",
   "metadata": {},
   "source": [
    "### Merging the datasets on the id column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d8d8d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge info_df and gamalytic_df\n",
    "merged_df = pd.merge(info_df, gamalytic_df, on='id', how='inner')\n",
    "\n",
    "# Aggregate DLCs (count per game)\n",
    "dlc_count = dlcs_df.groupby('id').size().reset_index(name='dlc_count')\n",
    "\n",
    "merged_df = pd.merge(merged_df, dlc_count, on='id', how='left')\n",
    "merged_df['dlc_count'] = merged_df['dlc_count'].fillna(0)\n",
    "\n",
    "# Add demo presence\n",
    "merged_df['hasDemo'] = merged_df['id'].isin(demos_df['id']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "08bf42cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69428 entries, 0 to 69427\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   69428 non-null  object \n",
      " 1   name                 69428 non-null  object \n",
      " 2   metacritic           2933 non-null   object \n",
      " 3   steam_achievements   69428 non-null  bool   \n",
      " 4   steam_trading_cards  69428 non-null  bool   \n",
      " 5   workshop_support     69428 non-null  bool   \n",
      " 6   genres               69324 non-null  object \n",
      " 7   achievements_total   37295 non-null  object \n",
      " 8   release_date         69426 non-null  object \n",
      " 9   supported_platforms  69428 non-null  object \n",
      " 10  price                69428 non-null  float64\n",
      " 11  copiesSold           69428 non-null  int64  \n",
      " 12  publisherClass       69428 non-null  object \n",
      " 13  reviewScore          69428 non-null  object \n",
      " 14  aiContent            0 non-null      float64\n",
      " 15  dlc_count            69428 non-null  float64\n",
      " 16  hasDemo              69428 non-null  int64  \n",
      "dtypes: bool(3), float64(3), int64(2), object(9)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a688b7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "name                       0\n",
       "metacritic             66495\n",
       "steam_achievements         0\n",
       "steam_trading_cards        0\n",
       "workshop_support           0\n",
       "genres                   104\n",
       "achievements_total     32133\n",
       "release_date               2\n",
       "supported_platforms        0\n",
       "price                      0\n",
       "copiesSold                 0\n",
       "publisherClass             0\n",
       "reviewScore                0\n",
       "aiContent              69428\n",
       "dlc_count                  0\n",
       "hasDemo                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7e6b4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e31ed",
   "metadata": {},
   "source": [
    "# Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "65d01ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Save to CSV files\n",
    "# # train_df.to_csv('train.csv', index=False)\n",
    "# # test_df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "94b0613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69428 entries, 0 to 69427\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   69428 non-null  object \n",
      " 1   name                 69428 non-null  object \n",
      " 2   metacritic           2933 non-null   object \n",
      " 3   steam_achievements   69428 non-null  bool   \n",
      " 4   steam_trading_cards  69428 non-null  bool   \n",
      " 5   workshop_support     69428 non-null  bool   \n",
      " 6   genres               69324 non-null  object \n",
      " 7   achievements_total   37295 non-null  object \n",
      " 8   release_date         69426 non-null  object \n",
      " 9   supported_platforms  69428 non-null  object \n",
      " 10  price                69428 non-null  float64\n",
      " 11  copiesSold           69428 non-null  int64  \n",
      " 12  publisherClass       69428 non-null  object \n",
      " 13  reviewScore          69428 non-null  object \n",
      " 14  aiContent            0 non-null      float64\n",
      " 15  dlc_count            69428 non-null  float64\n",
      " 16  hasDemo              69428 non-null  int64  \n",
      "dtypes: bool(3), float64(3), int64(2), object(9)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f4568",
   "metadata": {},
   "source": [
    "# Data wrangling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "67a992f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['metacritic'] = pd.to_numeric(df['metacritic'], errors='coerce').fillna(0)\n",
    "df['achievements_total'] = pd.to_numeric(df['achievements_total'], errors='coerce').fillna(0)\n",
    "df['genres'] = df['genres'].fillna('Unknown')\n",
    "df['release_date'] = df['release_date'].replace('Coming soon', pd.NA)\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df['release_year'] = df['release_date'].dt.year.fillna(df['release_date'].dt.year.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c6e0b179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "name                       0\n",
       "metacritic                 0\n",
       "steam_achievements         0\n",
       "steam_trading_cards        0\n",
       "workshop_support           0\n",
       "genres                     0\n",
       "achievements_total         0\n",
       "release_date            1223\n",
       "supported_platforms        0\n",
       "price                      0\n",
       "copiesSold                 0\n",
       "publisherClass             0\n",
       "reviewScore                0\n",
       "aiContent              69428\n",
       "dlc_count                  0\n",
       "hasDemo                    0\n",
       "release_year               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8bf97a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "name                       0\n",
       "metacritic                 0\n",
       "steam_achievements         0\n",
       "steam_trading_cards        0\n",
       "workshop_support           0\n",
       "genres                     0\n",
       "achievements_total         0\n",
       "release_date            1223\n",
       "supported_platforms        0\n",
       "price                      0\n",
       "copiesSold                 0\n",
       "publisherClass             0\n",
       "reviewScore                0\n",
       "aiContent              69428\n",
       "dlc_count                  0\n",
       "hasDemo                    0\n",
       "release_year               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "44aa6d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69428 entries, 0 to 69427\n",
      "Data columns (total 18 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   id                   69428 non-null  object        \n",
      " 1   name                 69428 non-null  object        \n",
      " 2   metacritic           69428 non-null  float64       \n",
      " 3   steam_achievements   69428 non-null  bool          \n",
      " 4   steam_trading_cards  69428 non-null  bool          \n",
      " 5   workshop_support     69428 non-null  bool          \n",
      " 6   genres               69428 non-null  object        \n",
      " 7   achievements_total   69428 non-null  float64       \n",
      " 8   release_date         68205 non-null  datetime64[ns]\n",
      " 9   supported_platforms  69428 non-null  object        \n",
      " 10  price                69428 non-null  float64       \n",
      " 11  copiesSold           69428 non-null  int64         \n",
      " 12  publisherClass       69428 non-null  object        \n",
      " 13  reviewScore          69428 non-null  object        \n",
      " 14  aiContent            0 non-null      float64       \n",
      " 15  dlc_count            69428 non-null  float64       \n",
      " 16  hasDemo              69428 non-null  int64         \n",
      " 17  release_year         69428 non-null  float64       \n",
      "dtypes: bool(3), datetime64[ns](1), float64(6), int64(2), object(6)\n",
      "memory usage: 8.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44006961",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c95b9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "current_year = datetime.now().year\n",
    "df['game_age'] = current_year - df['release_year']\n",
    "\n",
    "# 2. Price Categories\n",
    "df['price_category'] = pd.cut(\n",
    "    df['price'],\n",
    "    bins=[-1, 0, 5, 15, 30, 60, float('inf')],\n",
    "    labels=['Free', 'Low', 'Medium', 'High', 'Very High', 'Premium']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "30f01ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isWindows'] = df['supported_platforms'].apply(lambda x: 1 if 'windows' in str(x).lower() else 0)\n",
    "df['isMac'] = df['supported_platforms'].apply(lambda x: 1 if 'mac' in str(x).lower() else 0)\n",
    "df['isLinux'] = df['supported_platforms'].apply(lambda x: 1 if 'linux' in str(x).lower() else 0)\n",
    "df['num_platforms'] = df[['isWindows', 'isMac', 'isLinux']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "297afac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_per_dlc'] = df['price'] / (df['dlc_count'] + 1)\n",
    "df['achievements_per_dlc'] = df['achievements_total'] / (df['dlc_count'] + 1)\n",
    "\n",
    "# 5. Log Transformation\n",
    "df['log_copiesSold'] = np.log1p(df['copiesSold'].clip(lower=0))\n",
    "df['log_price'] = np.log1p(df['price'].clip(lower=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4f9ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(series, lower_quantile=0.01, upper_quantile=0.99):\n",
    "    lower = series.quantile(lower_quantile)\n",
    "    upper = series.quantile(upper_quantile)\n",
    "    return series.clip(lower=lower, upper=upper)\n",
    "\n",
    "df['copiesSold'] = cap_outliers(df['copiesSold'])\n",
    "df['price'] = cap_outliers(df['price'])\n",
    "df['achievements_total'] = cap_outliers(df['achievements_total'])\n",
    "df['dlc_count'] = cap_outliers(df['dlc_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5808fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['steam_achievements', 'steam_trading_cards', 'workshop_support','reviewScore']\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df[col] = encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c884d",
   "metadata": {},
   "source": [
    "### Copiessold outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "290133d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.942800e+04\n",
       "mean     3.494762e+04\n",
       "std      1.654204e+05\n",
       "min      1.000000e+00\n",
       "25%      6.000000e+01\n",
       "50%      4.570000e+02\n",
       "75%      3.955000e+03\n",
       "max      1.352608e+06\n",
       "Name: copiesSold, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['copiesSold'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06125664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5782.5\n",
      "9797.5\n"
     ]
    }
   ],
   "source": [
    "Q1 = df['copiesSold'].quantile(0.25)\n",
    "Q3 = df['copiesSold'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier thresholds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Detect outliers\n",
    "outliers = df[(df['copiesSold'] < lower_bound) | (df['copiesSold'] > upper_bound)]\n",
    "print(lower_bound)\n",
    "print(upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f3b9c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['copiesSold'] <= 0, 'copiesSold'] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f5c12638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = (train_df[train_df['copiesSold'] <= 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd0667",
   "metadata": {},
   "source": [
    "## Price outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "17611ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    69428.000000\n",
       "mean         7.342479\n",
       "std          8.303669\n",
       "min          0.000000\n",
       "25%          0.990000\n",
       "50%          4.990000\n",
       "75%          9.990000\n",
       "max         44.990000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "26ffd015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.51\n",
      "23.490000000000002\n"
     ]
    }
   ],
   "source": [
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier thresholds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Detect outliers\n",
    "outliers = df[(df['price'] < lower_bound) | (df['price'] > upper_bound)]\n",
    "print(lower_bound)\n",
    "print(upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e9ef8384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>metacritic</th>\n",
       "      <th>steam_achievements</th>\n",
       "      <th>steam_trading_cards</th>\n",
       "      <th>workshop_support</th>\n",
       "      <th>genres</th>\n",
       "      <th>achievements_total</th>\n",
       "      <th>release_date</th>\n",
       "      <th>supported_platforms</th>\n",
       "      <th>...</th>\n",
       "      <th>game_age</th>\n",
       "      <th>price_category</th>\n",
       "      <th>isWindows</th>\n",
       "      <th>isMac</th>\n",
       "      <th>isLinux</th>\n",
       "      <th>num_platforms</th>\n",
       "      <th>price_per_dlc</th>\n",
       "      <th>achievements_per_dlc</th>\n",
       "      <th>log_copiesSold</th>\n",
       "      <th>log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, name, metacritic, steam_achievements, steam_trading_cards, workshop_support, genres, achievements_total, release_date, supported_platforms, price, copiesSold, publisherClass, reviewScore, aiContent, dlc_count, hasDemo, release_year, game_age, price_category, isWindows, isMac, isLinux, num_platforms, price_per_dlc, achievements_per_dlc, log_copiesSold, log_price]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 28 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['price'] > 200 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6993a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['price'] <= 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6d423d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres_split'] = df['genres'].str.split(',')\n",
    "\n",
    "exploded_genres = df.explode('genres_split')\n",
    "exploded_genres['genres_split'] = exploded_genres['genres_split'].str.strip()\n",
    "genre_counts = exploded_genres['genres_split'].value_counts()\n",
    "\n",
    "\n",
    "rare_genres = genre_counts[genre_counts < 5000].index\n",
    "exploded_genres['genres_split'] = exploded_genres['genres_split'].apply(lambda x: 'Other_genres' if x in rare_genres else x)\n",
    "\n",
    "df['genres'] = (\n",
    "    exploded_genres\n",
    "    .groupby(exploded_genres.index)['genres_split']\n",
    "    .apply(lambda x: ', '.join(sorted(set(x))))\n",
    ")\n",
    "\n",
    "df.drop(columns=['genres_split'],inplace=True)\n",
    "df['genre_diversity'] = df['genres'].str.split(',').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5c11b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres_list'] = df['genres'].str.split(', ')\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "genres_encoded = mlb.fit_transform(list(df['genres_list']))\n",
    "genres_df = pd.DataFrame(genres_encoded, columns=mlb.classes_,index=df.index)\n",
    "\n",
    "df = pd.concat([df, genres_df], axis=1)\n",
    "df.drop(columns=['genres_list','genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0c9aaf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_encoder = LabelEncoder()\n",
    "df['temp_reviewScore'] = temp_encoder.fit_transform(df['reviewScore'])\n",
    "publisher_success = df.groupby('publisherClass')['temp_reviewScore'].mean().to_dict()\n",
    "df['publisher_success_score'] = df['publisherClass'].map(publisher_success)\n",
    "df.drop(columns=['temp_reviewScore'], inplace=True)\n",
    "\n",
    "# 7. NEW: Platform Exclusivity\n",
    "df['is_exclusive'] = (df['num_platforms'] == 1).astype(int)\n",
    "\n",
    "# 8. NEW: Release Seasonality\n",
    "df['release_month'] = df['release_date'].dt.month.fillna(df['release_date'].dt.month.mode()[0])\n",
    "df['release_quarter'] = df['release_date'].dt.quarter.fillna(df['release_date'].dt.quarter.mode()[0])\n",
    "\n",
    "# 9. NEW: Price-to-CopiesSold Ratio\n",
    "df['price_to_copies_ratio'] = df['price'] / (df['log_copiesSold'] + 1e-6)\n",
    "\n",
    "# 10. NEW: Game Complexity Proxy\n",
    "df['game_complexity'] = (\n",
    "    df['achievements_total'] / (df['achievements_total'].max() + 1e-6) +\n",
    "    df['dlc_count'] / (df['dlc_count'].max() + 1e-6) +\n",
    "    df['genre_diversity'] / (df['genre_diversity'].max() + 1e-6)\n",
    ")\n",
    "\n",
    "# 11. NEW: Metacritic Binary\n",
    "df['has_metacritic'] = (df['metacritic'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e293797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['publisherClass', 'price_category'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f9eecf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_cols = mlb.classes_\n",
    "genre_popularity = {}\n",
    "for genre in genre_cols:\n",
    "    mask = df[genre] == 1\n",
    "    genre_popularity[genre] = df[mask]['copiesSold'].mean() if mask.sum() > 0 else 0\n",
    "df['genre_popularity'] = df[genre_cols].dot(list(genre_popularity.values())) / df[genre_cols].sum(axis=1)\n",
    "\n",
    "# NEW: Free-to-Play Interaction\n",
    "df['free_to_play_interaction'] = df['price_category_Free'] * df['Free To Play']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a45fcfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69428 entries, 0 to 69427\n",
      "Data columns (total 55 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   id                        69428 non-null  object        \n",
      " 1   name                      69428 non-null  object        \n",
      " 2   metacritic                69428 non-null  float64       \n",
      " 3   steam_achievements        69428 non-null  int64         \n",
      " 4   steam_trading_cards       69428 non-null  int64         \n",
      " 5   workshop_support          69428 non-null  int64         \n",
      " 6   achievements_total        69428 non-null  float64       \n",
      " 7   release_date              68205 non-null  datetime64[ns]\n",
      " 8   supported_platforms       69428 non-null  object        \n",
      " 9   price                     69428 non-null  float64       \n",
      " 10  copiesSold                69428 non-null  float64       \n",
      " 11  reviewScore               69428 non-null  int64         \n",
      " 12  aiContent                 0 non-null      float64       \n",
      " 13  dlc_count                 69428 non-null  float64       \n",
      " 14  hasDemo                   69428 non-null  int64         \n",
      " 15  release_year              69428 non-null  float64       \n",
      " 16  game_age                  69428 non-null  float64       \n",
      " 17  isWindows                 69428 non-null  int64         \n",
      " 18  isMac                     69428 non-null  int64         \n",
      " 19  isLinux                   69428 non-null  int64         \n",
      " 20  num_platforms             69428 non-null  int64         \n",
      " 21  price_per_dlc             69428 non-null  float64       \n",
      " 22  achievements_per_dlc      69428 non-null  float64       \n",
      " 23  log_copiesSold            69428 non-null  float64       \n",
      " 24  log_price                 69428 non-null  float64       \n",
      " 25  genre_diversity           69428 non-null  int64         \n",
      " 26  Action                    69428 non-null  int64         \n",
      " 27  Adventure                 69428 non-null  int64         \n",
      " 28  Casual                    69428 non-null  int64         \n",
      " 29  Early Access              69428 non-null  int64         \n",
      " 30  Free To Play              69428 non-null  int64         \n",
      " 31  Indie                     69428 non-null  int64         \n",
      " 32  Other_genres              69428 non-null  int64         \n",
      " 33  RPG                       69428 non-null  int64         \n",
      " 34  Simulation                69428 non-null  int64         \n",
      " 35  Strategy                  69428 non-null  int64         \n",
      " 36  publisher_success_score   69428 non-null  float64       \n",
      " 37  is_exclusive              69428 non-null  int64         \n",
      " 38  release_month             69428 non-null  float64       \n",
      " 39  release_quarter           69428 non-null  float64       \n",
      " 40  price_to_copies_ratio     69428 non-null  float64       \n",
      " 41  game_complexity           69428 non-null  float64       \n",
      " 42  has_metacritic            69428 non-null  int64         \n",
      " 43  publisherClass_AA         69428 non-null  int64         \n",
      " 44  publisherClass_AAA        69428 non-null  int64         \n",
      " 45  publisherClass_Hobbyist   69428 non-null  int64         \n",
      " 46  publisherClass_Indie      69428 non-null  int64         \n",
      " 47  price_category_Free       69428 non-null  int64         \n",
      " 48  price_category_Low        69428 non-null  int64         \n",
      " 49  price_category_Medium     69428 non-null  int64         \n",
      " 50  price_category_High       69428 non-null  int64         \n",
      " 51  price_category_Very High  69428 non-null  int64         \n",
      " 52  price_category_Premium    69428 non-null  int64         \n",
      " 53  genre_popularity          69428 non-null  float64       \n",
      " 54  free_to_play_interaction  69428 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(18), int64(33), object(3)\n",
      "memory usage: 29.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fd3cb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'metacritic', 'steam_achievements', 'steam_trading_cards', 'workshop_support',\n",
    "    'achievements_total', 'dlc_count', 'hasDemo', 'release_year', 'game_age',\n",
    "    'isWindows', 'isMac', 'isLinux', 'num_platforms', 'price_per_dlc',\n",
    "    'achievements_per_dlc', 'log_copiesSold', 'log_price', 'genre_diversity',\n",
    "    'publisherClass_AA', 'publisherClass_AAA', 'publisherClass_Hobbyist',\n",
    "    'publisherClass_Indie', 'price_category_Free', 'price_category_Low',\n",
    "    'price_category_Medium', 'price_category_High', 'price_category_Very High',\n",
    "    'price_category_Premium', 'Action', 'Adventure', 'Casual', 'Early Access',\n",
    "    'Free To Play', 'Indie', 'Other_genres', 'RPG', 'Simulation', 'Strategy',\n",
    "    'publisher_success_score', 'is_exclusive', 'release_month', 'release_quarter',\n",
    "    'price_to_copies_ratio', 'game_complexity', 'has_metacritic',\n",
    "    'genre_popularity', 'free_to_play_interaction'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1d31c203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da937f90",
   "metadata": {},
   "source": [
    "### Chi_squared "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "401ee43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df['reviewScore']\n",
    "scaler = StandardScaler()\n",
    "# numerical_cols = [\n",
    "#     'metacritic', 'achievements_total', 'dlc_count', 'release_year', 'game_age',\n",
    "#     'num_platforms', 'price_per_dlc', 'achievements_per_dlc', 'log_copiesSold',\n",
    "#     'log_price', 'genre_diversity'\n",
    "# ]\n",
    "numerical_cols = [\n",
    "    'metacritic', 'achievements_total', 'dlc_count', 'release_year', 'game_age',\n",
    "    'num_platforms', 'price_per_dlc', 'achievements_per_dlc', 'log_copiesSold',\n",
    "    'log_price', 'genre_diversity', 'publisher_success_score', 'release_month',\n",
    "    'release_quarter', 'price_to_copies_ratio', 'game_complexity',\n",
    "    'genre_popularity'\n",
    "]\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "# Apply Chi-Squared\n",
    "# chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
    "# chi2_selector.fit(X, y)\n",
    "# feature_scores = pd.DataFrame({'Feature': columns, 'Chi2 Score': chi2_selector.scores_})\n",
    "# print(feature_scores.sort_values(by='Chi2 Score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "44648632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['metacritic', 'steam_achievements', 'steam_trading_cards', 'workshop_support', 'achievements_total', 'dlc_count', 'hasDemo', 'release_year', 'game_age', 'num_platforms', 'price_per_dlc', 'achievements_per_dlc', 'log_copiesSold', 'log_price', 'publisherClass_AA', 'publisherClass_AAA', 'publisherClass_Hobbyist', 'publisherClass_Indie', 'price_category_Free', 'price_category_Low', 'price_category_High', 'price_category_Very High', 'Free To Play', 'Simulation', 'publisher_success_score', 'price_to_copies_ratio', 'game_complexity', 'has_metacritic', 'genre_popularity', 'free_to_play_interaction']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "for col in numerical_cols:\n",
    "    min_val = X_scaled[col].min()\n",
    "    if min_val < 0:\n",
    "        X_scaled[col] = X_scaled[col] - min_val + 1e-6  # Small constant to avoid zero\n",
    "    X_scaled[col] = X_scaled[col].clip(lower=0)  # Ensure no negatives\n",
    "\n",
    "# Handle any infinities or NaNs\n",
    "X_scaled = X_scaled.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "# Apply SMOTE to the top 5 classes\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Feature Selection with Chi-Squared\n",
    "chi2_selector = SelectKBest(score_func=chi2, k = 30)\n",
    "X_selected = chi2_selector.fit_transform(X_scaled, y)\n",
    "selected_features = [features[i] for i in chi2_selector.get_support(indices=True)]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee4624",
   "metadata": {},
   "source": [
    "### get top features score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4c16b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features Ordered by Chi-Squared Score:\n",
      "                      Feature    Chi2 Score\n",
      "0                 metacritic  34354.791387\n",
      "38   publisher_success_score  20234.418942\n",
      "15            log_copiesSold  19157.982918\n",
      "4         achievements_total   6911.607805\n",
      "42     price_to_copies_ratio   6599.498451\n",
      "44            has_metacritic   6136.655316\n",
      "5                  dlc_count   6076.778831\n",
      "8                   game_age   5703.320383\n",
      "20   publisherClass_Hobbyist   5538.923640\n",
      "21      publisherClass_Indie   4731.702782\n",
      "43           game_complexity   3772.311629\n",
      "18         publisherClass_AA   3275.535518\n",
      "23        price_category_Low   2567.286635\n",
      "25       price_category_High   2421.790984\n",
      "14      achievements_per_dlc   2076.886110\n",
      "2        steam_trading_cards   1954.491054\n",
      "19        publisherClass_AAA   1726.283271\n",
      "22       price_category_Free   1477.489794\n",
      "13             price_per_dlc   1372.487180\n",
      "46  free_to_play_interaction   1158.722866\n",
      "12             num_platforms   1157.630766\n",
      "32              Free To Play   1137.874026\n",
      "1         steam_achievements    982.051761\n",
      "7               release_year    960.199755\n",
      "45          genre_popularity    866.955390\n",
      "36                Simulation    825.616988\n",
      "26  price_category_Very High    786.113296\n",
      "16                 log_price    646.399099\n",
      "6                    hasDemo    585.785372\n",
      "3           workshop_support    576.061172\n",
      "10                     isMac    556.166905\n",
      "34              Other_genres    529.764514\n",
      "11                   isLinux    395.219092\n",
      "30                    Casual    372.340986\n",
      "17           genre_diversity    312.140419\n",
      "35                       RPG    297.262761\n",
      "39              is_exclusive    251.036956\n",
      "31              Early Access    168.969247\n",
      "27    price_category_Premium    140.389672\n",
      "37                  Strategy    127.377479\n",
      "33                     Indie    100.254696\n",
      "29                 Adventure     85.419256\n",
      "24     price_category_Medium     48.652689\n",
      "40             release_month     33.098580\n",
      "28                    Action     26.860801\n",
      "41           release_quarter     24.486282\n",
      "9                  isWindows      0.001156\n",
      "\n",
      "Top 20 Features:\n",
      "                      Feature    Chi2 Score\n",
      "0                 metacritic  34354.791387\n",
      "38   publisher_success_score  20234.418942\n",
      "15            log_copiesSold  19157.982918\n",
      "4         achievements_total   6911.607805\n",
      "42     price_to_copies_ratio   6599.498451\n",
      "44            has_metacritic   6136.655316\n",
      "5                  dlc_count   6076.778831\n",
      "8                   game_age   5703.320383\n",
      "20   publisherClass_Hobbyist   5538.923640\n",
      "21      publisherClass_Indie   4731.702782\n",
      "43           game_complexity   3772.311629\n",
      "18         publisherClass_AA   3275.535518\n",
      "23        price_category_Low   2567.286635\n",
      "25       price_category_High   2421.790984\n",
      "14      achievements_per_dlc   2076.886110\n",
      "2        steam_trading_cards   1954.491054\n",
      "19        publisherClass_AAA   1726.283271\n",
      "22       price_category_Free   1477.489794\n",
      "13             price_per_dlc   1372.487180\n",
      "46  free_to_play_interaction   1158.722866\n"
     ]
    }
   ],
   "source": [
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Chi2 Score': chi2_selector.scores_\n",
    "})\n",
    "\n",
    "# Sort features by Chi2 Score in descending order\n",
    "top_features = feature_scores.sort_values(by='Chi2 Score', ascending=False)\n",
    "\n",
    "# Print the top features\n",
    "print(\"Top Features Ordered by Chi-Squared Score:\\n\", top_features)\n",
    "\n",
    "# Optionally, get the top N features (e.g., top 20)\n",
    "N = 20\n",
    "print(f\"\\nTop {N} Features:\\n\", top_features.head(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "69c88126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e11fc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features = feature_scores.sort_values(by='Chi2 Score', ascending=False).head(47)['Feature'].tolist()\n",
    "# X_selected = X[top_features] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "860127fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1c756b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_chi2 = X.copy()\n",
    "# for col in X_chi2.columns:\n",
    "#     min_val = X_chi2[col].min()\n",
    "#     if min_val < 0:\n",
    "#         X_chi2[col] = X_chi2[col] - min_val\n",
    "\n",
    "# selector = SelectKBest(score_func=chi2, k=10)\n",
    "# X_selected = selector.fit_transform(X_chi2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f001a",
   "metadata": {},
   "source": [
    "### Hypertuning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd45d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost = CatBoostClassifier(verbose=0, random_state=42)\n",
    "# param_grid = {\n",
    "#     'depth': [6, 8],\n",
    "#     'learning_rate': [0.01, 0.05],\n",
    "#     'iterations': [500, 1000]\n",
    "# }\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=catboost,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best Model\n",
    "# best_model = grid_search.best_estimator_\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7315ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2358b39",
   "metadata": {},
   "source": [
    "- random state 53 ==> 59.82% \n",
    "- random state 57 ==> 59.98%\n",
    "- random state 55 ==> 60.04%\n",
    "- random state 54 1400 iter ==> 60.35%\n",
    "- random state 54 1500 iter ==> 60.52%\n",
    "- random state 54 test size 15% 1400 iter ==> 60.60 %\n",
    "- random state 54 test size 20% 1500 iter 0.08 lr ==> 60.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bedb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_df[selected_features], y, test_size=0.05, random_state=54)\n",
    "\n",
    "# catboost_model = CatBoostClassifier(verbose=0,bagging_temperature=0, depth= 6, iterations= 1500, l2_leaf_reg= 5, learning_rate=0.08)  \n",
    "# catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluation\n",
    "# y_pred = catboost_model.predict(X_test)\n",
    "# print(\"CatBoost Accuracy:\", accuracy_score(y_test, y_pred)*100)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe045a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_model =xgb.XGBClassifier(colsample_bytree= 0.8, learning_rate= 0.09, max_depth= 5, n_estimators= 500, subsample= 0.8)  \n",
    "# xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluation\n",
    "# y_pred = xgboost_model.predict(X_test)\n",
    "# print(\"xgb Accuracy:\", accuracy_score(y_test, y_pred)*100)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bdd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# lightgbm_model = LGBMClassifier(\n",
    "#     colsample_bytree=0.8,\n",
    "#     learning_rate=0.08,\n",
    "#     num_leaves=80,\n",
    "#     n_estimators=500,\n",
    "#     subsample=0.8,\n",
    "#     random_state=54\n",
    "# )\n",
    "\n",
    "# # Fit the model\n",
    "# lightgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluation\n",
    "# y_pred = lightgbm_model.predict(X_test)\n",
    "# print(\"LightGBM Accuracy:\", accuracy_score(y_test, y_pred) * 100)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving the best model file \n",
    "# with open('catboost_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(catboost_model, file)\n",
    "\n",
    "# print(\"CatBoost model saved to 'catboost_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13886 entries, 58447 to 48106\n",
      "Data columns (total 38 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   id                    13886 non-null  object        \n",
      " 1   name                  13886 non-null  object        \n",
      " 2   metacritic            13886 non-null  float64       \n",
      " 3   steam_achievements    13886 non-null  bool          \n",
      " 4   steam_trading_cards   13886 non-null  bool          \n",
      " 5   workshop_support      13886 non-null  bool          \n",
      " 6   achievements_total    13886 non-null  float64       \n",
      " 7   release_date          13631 non-null  datetime64[ns]\n",
      " 8   supported_platforms   13886 non-null  object        \n",
      " 9   price                 13886 non-null  float64       \n",
      " 10  copiesSold            13886 non-null  int64         \n",
      " 11  publisherClass        13886 non-null  object        \n",
      " 12  reviewScore           13886 non-null  object        \n",
      " 13  aiContent             0 non-null      float64       \n",
      " 14  dlc_count             13886 non-null  float64       \n",
      " 15  hasDemo               13886 non-null  int64         \n",
      " 16  release_year          13886 non-null  float64       \n",
      " 17  game_age              13886 non-null  float64       \n",
      " 18  price_category        13886 non-null  category      \n",
      " 19  isWindows             13886 non-null  int64         \n",
      " 20  isMac                 13886 non-null  int64         \n",
      " 21  isLinux               13886 non-null  int64         \n",
      " 22  num_platforms         13886 non-null  int64         \n",
      " 23  price_per_dlc         13886 non-null  float64       \n",
      " 24  achievements_per_dlc  13886 non-null  float64       \n",
      " 25  log_copiesSold        13886 non-null  float64       \n",
      " 26  log_price             13886 non-null  float64       \n",
      " 27  genre_diversity       13886 non-null  int64         \n",
      " 28  0                     13886 non-null  int64         \n",
      " 29  1                     13886 non-null  int64         \n",
      " 30  2                     13886 non-null  int64         \n",
      " 31  3                     13886 non-null  int64         \n",
      " 32  4                     13886 non-null  int64         \n",
      " 33  5                     13886 non-null  int64         \n",
      " 34  6                     13886 non-null  int64         \n",
      " 35  7                     13886 non-null  int64         \n",
      " 36  8                     13886 non-null  int64         \n",
      " 37  9                     13886 non-null  int64         \n",
      "dtypes: bool(3), category(1), datetime64[ns](1), float64(11), int64(17), object(5)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d07508",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'genres'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'genres'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mmetacritic\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(test_df[\u001b[33m'\u001b[39m\u001b[33mmetacritic\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m).fillna(\u001b[32m0\u001b[39m)\n\u001b[32m      6\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33machievements_total\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(test_df[\u001b[33m'\u001b[39m\u001b[33machievements_total\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m).fillna(\u001b[32m0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mgenres\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgenres\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.fillna(\u001b[33m'\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mrelease_date\u001b[39m\u001b[33m'\u001b[39m] = test_df[\u001b[33m'\u001b[39m\u001b[33mrelease_date\u001b[39m\u001b[33m'\u001b[39m].replace(\u001b[33m'\u001b[39m\u001b[33mComing soon\u001b[39m\u001b[33m'\u001b[39m, pd.NA)\n\u001b[32m      9\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mrelease_date\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(test_df[\u001b[33m'\u001b[39m\u001b[33mrelease_date\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'genres'"
     ]
    }
   ],
   "source": [
    "# Save training set's mode for release_year\n",
    "train_release_year_mode = train_df['release_date'].dt.year.mode()[0]\n",
    "\n",
    "# Handle test set\n",
    "test_df['metacritic'] = pd.to_numeric(test_df['metacritic'], errors='coerce').fillna(0)\n",
    "test_df['achievements_total'] = pd.to_numeric(test_df['achievements_total'], errors='coerce').fillna(0)\n",
    "test_df['genres'] = test_df['genres'].fillna('Unknown')\n",
    "test_df['release_date'] = test_df['release_date'].replace('Coming soon', pd.NA)\n",
    "test_df['release_date'] = pd.to_datetime(test_df['release_date'], errors='coerce')\n",
    "test_df['release_year'] = test_df['release_date'].dt.year.fillna(train_release_year_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:909: UserWarning: unknown class(es) ['Animation & Modeling', 'Audio Production', 'Design & Illustration', 'Education', 'Gore', 'Massively Multiplayer', 'Nudity', 'Photo Editing', 'Racing', 'Sexual Content', 'Software Training', 'Sports', 'Unknown', 'Utilities', 'Video Production', 'Violent', 'Web Publishing'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m test_df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mgenres_list\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgenres\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgenres_split\u001b[39m\u001b[33m'\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33msteam_achievements\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msteam_trading_cards\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mworkshop_support\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mreviewScore\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     test_df[col] = \u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mpublisher_success_score\u001b[39m\u001b[33m'\u001b[39m] = test_df[\u001b[33m'\u001b[39m\u001b[33mpublisherClass\u001b[39m\u001b[33m'\u001b[39m].map(publisher_success)\n\u001b[32m     43\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mis_exclusive\u001b[39m\u001b[33m'\u001b[39m] = (test_df[\u001b[33m'\u001b[39m\u001b[33mnum_platforms\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m1\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:127\u001b[39m, in \u001b[36mLabelEncoder.transform\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Transform labels to normalized encoding.\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03m        Labels as normalized encodings.\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m     xp, _ = get_namespace(y)\n\u001b[32m    129\u001b[39m     y = column_or_1d(y, dtype=\u001b[38;5;28mself\u001b[39m.classes_.dtype, warn=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1757\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1754\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[31mNotFittedError\u001b[39m: This LabelEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "e=LabelEncoder()\n",
    "current_year = datetime.now().year\n",
    "test_df['game_age'] = current_year - test_df['release_year']\n",
    "\n",
    "test_df['price_category'] = pd.cut(\n",
    "    test_df['price'],\n",
    "    bins=[-1, 0, 5, 15, 30, 60, float('inf')],\n",
    "    labels=['Free', 'Low', 'Medium', 'High', 'Very High', 'Premium']\n",
    ")\n",
    "\n",
    "test_df['isWindows'] = test_df['supported_platforms'].apply(lambda x: 1 if 'windows' in str(x).lower() else 0)\n",
    "test_df['isMac'] = test_df['supported_platforms'].apply(lambda x: 1 if 'mac' in str(x).lower() else 0)\n",
    "test_df['isLinux'] = test_df['supported_platforms'].apply(lambda x: 1 if 'linux' in str(x).lower() else 0)\n",
    "test_df['num_platforms'] = test_df[['isWindows', 'isMac', 'isLinux']].sum(axis=1)\n",
    "\n",
    "test_df['price_per_dlc'] = test_df['price'] / (test_df['dlc_count'] + 1)\n",
    "test_df['achievements_per_dlc'] = test_df['achievements_total'] / (test_df['dlc_count'] + 1)\n",
    "test_df['log_copiesSold'] = np.log1p(test_df['copiesSold'].clip(lower=0))\n",
    "test_df['log_price'] = np.log1p(test_df['price'].clip(lower=0))\n",
    "\n",
    "test_df['genres_split'] = test_df['genres'].str.split(',')\n",
    "test_df['genres_split'] = test_df['genres_split'].apply(lambda x: [g.strip() for g in x])\n",
    "\n",
    "rare_genres = set(train_df.columns) - set(['genres_split', 'genres_list']) - set(test_df.columns)\n",
    "test_df['genres_split'] = test_df['genres_split'].apply(\n",
    "    lambda x: ['Other_genres' if g in rare_genres else g for g in x]\n",
    ")\n",
    "test_df['genres'] = test_df['genres_split'].apply(lambda x: ', '.join(sorted(set(x))))\n",
    "test_df['genre_diversity'] = test_df['genres'].str.split(',').apply(len)\n",
    "\n",
    "test_df['genres_list'] = test_df['genres'].str.split(', ')\n",
    "genres_encoded = mlb.transform(list(test_df['genres_list']))\n",
    "genres_df = pd.DataFrame(genres_encoded, columns=mlb.classes, index=test_df.index)\n",
    "test_df = pd.concat([test_df, genres_df], axis=1)\n",
    "test_df.drop(columns=['genres_list', 'genres', 'genres_split'], inplace=True)\n",
    "\n",
    "for col in ['steam_achievements', 'steam_trading_cards', 'workshop_support', 'reviewScore']:\n",
    "    test_df[col] = e.transform(test_df[col])\n",
    "\n",
    "test_df['publisher_success_score'] = test_df['publisherClass'].map(publisher_success)\n",
    "\n",
    "test_df['is_exclusive'] = (test_df['num_platforms'] == 1).astype(int)\n",
    "\n",
    "\n",
    "test_df['release_month'] = test_df['release_date'].dt.month.fillna(test_df['release_date'].dt.month.mode()[0])\n",
    "test_df['release_quarter'] = test_df['release_date'].dt.quarter.fillna(test_df['release_date'].dt.quarter.mode()[0])\n",
    "\n",
    "test_df['price_to_copies_ratio'] = test_df['price'] / (test_df['log_copiesSold'] + 1e-6)\n",
    "\n",
    "\n",
    "test_df['game_complexity'] = (\n",
    "    test_df['achievements_total'] / (train_df['achievements_total'].max() + 1e-6) +\n",
    "    test_df['dlc_count'] / (train_df['dlc_count'].max() + 1e-6) +\n",
    "    test_df['genre_diversity'] / (train_df['genre_diversity'].max() + 1e-6)\n",
    ")\n",
    "\n",
    "\n",
    "test_df['has_metacritic'] = (test_df['metacritic'] > 0).astype(int)\n",
    "\n",
    "\n",
    "test_df = pd.get_dummies(test_df, columns=['publisherClass', 'price_category'], dtype=int)\n",
    "\n",
    "test_df['genre_popularity'] = test_df[genre_cols].dot(list(genre_popularity.values())) / test_df[genre_cols].sum(axis=1)\n",
    "\n",
    "if 'price_category_Free' in test_df.columns and 'Free To Play' in test_df.columns:\n",
    "    test_df['free_to_play_interaction'] = test_df['price_category_Free'] * test_df['Free To Play']\n",
    "else:\n",
    "    test_df['free_to_play_interaction'] = 0\n",
    "\n",
    "\n",
    "test_df = test_df[train_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4bbbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['release_year', 'game_age', 'isWindows', 'isMac', 'isLinux', 'num_platforms', 'price_per_dlc', 'achievements_per_dlc', 'log_copiesSold', 'log_price', 'genre_diversity', 'publisherClass_AA', 'publisherClass_AAA', 'publisherClass_Hobbyist', 'publisherClass_Indie', 'price_category_Free', 'price_category_Low', 'price_category_Medium', 'price_category_High', 'price_category_Very High', 'price_category_Premium', 'Action', 'Adventure', 'Casual', 'Early Access', 'Free To Play', 'Indie', 'Other_genres', 'RPG', 'Simulation', 'Strategy', 'publisher_success_score', 'is_exclusive', 'release_month', 'release_quarter', 'price_to_copies_ratio', 'game_complexity', 'has_metacritic', 'genre_popularity', 'free_to_play_interaction'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[207]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      1\u001b[39m features = [\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmetacritic\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msteam_achievements\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msteam_trading_cards\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mworkshop_support\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33machievements_total\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdlc_count\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhasDemo\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrelease_year\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgame_age\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgenre_popularity\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfree_to_play_interaction\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     14\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m X = \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     20\u001b[39m numerical_cols = [\n\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmetacritic\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33machievements_total\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdlc_count\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrelease_year\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgame_age\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     22\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnum_platforms\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mprice_per_dlc\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33machievements_per_dlc\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlog_copiesSold\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgenre_popularity\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     26\u001b[39m ]\n\u001b[32m     29\u001b[39m X_scaled = X.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['release_year', 'game_age', 'isWindows', 'isMac', 'isLinux', 'num_platforms', 'price_per_dlc', 'achievements_per_dlc', 'log_copiesSold', 'log_price', 'genre_diversity', 'publisherClass_AA', 'publisherClass_AAA', 'publisherClass_Hobbyist', 'publisherClass_Indie', 'price_category_Free', 'price_category_Low', 'price_category_Medium', 'price_category_High', 'price_category_Very High', 'price_category_Premium', 'Action', 'Adventure', 'Casual', 'Early Access', 'Free To Play', 'Indie', 'Other_genres', 'RPG', 'Simulation', 'Strategy', 'publisher_success_score', 'is_exclusive', 'release_month', 'release_quarter', 'price_to_copies_ratio', 'game_complexity', 'has_metacritic', 'genre_popularity', 'free_to_play_interaction'] not in index\""
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    'metacritic', 'steam_achievements', 'steam_trading_cards', 'workshop_support',\n",
    "    'achievements_total', 'dlc_count', 'hasDemo', 'release_year', 'game_age',\n",
    "    'isWindows', 'isMac', 'isLinux', 'num_platforms', 'price_per_dlc',\n",
    "    'achievements_per_dlc', 'log_copiesSold', 'log_price', 'genre_diversity',\n",
    "    'publisherClass_AA', 'publisherClass_AAA', 'publisherClass_Hobbyist',\n",
    "    'publisherClass_Indie', 'price_category_Free', 'price_category_Low',\n",
    "    'price_category_Medium', 'price_category_High', 'price_category_Very High',\n",
    "    'price_category_Premium', 'Action', 'Adventure', 'Casual', 'Early Access',\n",
    "    'Free To Play', 'Indie', 'Other_genres', 'RPG', 'Simulation', 'Strategy',\n",
    "    'publisher_success_score', 'is_exclusive', 'release_month', 'release_quarter',\n",
    "    'price_to_copies_ratio', 'game_complexity', 'has_metacritic',\n",
    "    'genre_popularity', 'free_to_play_interaction'\n",
    "]\n",
    "\n",
    "\n",
    "X = train_df[features]\n",
    "\n",
    "\n",
    "numerical_cols = [\n",
    "    'metacritic', 'achievements_total', 'dlc_count', 'release_year', 'game_age',\n",
    "    'num_platforms', 'price_per_dlc', 'achievements_per_dlc', 'log_copiesSold',\n",
    "    'log_price', 'genre_diversity', 'publisher_success_score', 'release_month',\n",
    "    'release_quarter', 'price_to_copies_ratio', 'game_complexity',\n",
    "    'genre_popularity'\n",
    "]\n",
    "\n",
    "\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "for col in numerical_cols:\n",
    "    min_val = X_scaled[col].min()\n",
    "    if min_val < 0:\n",
    "        X_scaled[col] = X_scaled[col] - min_val + 1e-6  # Small constant to avoid zero\n",
    "    X_scaled[col] = X_scaled[col].clip(lower=0)  # Ensure no negatives\n",
    "\n",
    "\n",
    "# Feature Selection with Chi-Squared\n",
    "chi2_selector = SelectKBest(score_func=chi2, k=30)\n",
    "X_selected = chi2_selector.fit_transform(X_scaled, y)\n",
    "selected_features = [features[i] for i in chi2_selector.get_support(indices=True)]\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ce3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55542\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df[selected_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f3cab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7df002",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =  train_df[selected_features] \n",
    "y_test = test_df['reviewScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab761dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('catboost_model.pkl', 'rb') as file:\n",
    "    catboost_model = pickle.load(file)\n",
    "\n",
    "# 3. Make predictions  \n",
    "predictions = catboost_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46717e1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [13886, 55542]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[204]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_test \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m catboost_model.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33mCatBoostClassifier\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m         accuracy = \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m catboost_model.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33mCatBoostRegressor\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:227\u001b[39m, in \u001b[36maccuracy_score\u001b[39m\u001b[34m(y_true, y_pred, normalize, sample_weight)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[32m    226\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type.startswith(\u001b[33m\"\u001b[39m\u001b[33mmultilabel\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m type_true = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [13886, 55542]"
     ]
    }
   ],
   "source": [
    "if y_test is not None:\n",
    "    if catboost_model.__class__.__name__ == 'CatBoostClassifier':\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    elif catboost_model.__class__.__name__ == 'CatBoostRegressor':\n",
    "        rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "    else:\n",
    "        print(\"Unknown model type.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb0ca2",
   "metadata": {},
   "source": [
    "\n",
    "- Best CatBoost Parameters: {'bagging_temperature': 0, 'depth': 6, 'iterations': 1500, 'l2_leaf_reg': 5, 'learning_rate': 0.05}\n",
    "\n",
    "- Best XGBoost Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 500, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db2b5f",
   "metadata": {},
   "source": [
    "### Hypertuning 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "# catboost = CatBoostClassifier(verbose=0, random_state=42)\n",
    "# catboost_param_grid = {\n",
    "#     'depth': [4, 6, 8, 10],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'iterations': [500, 1000, 1500],\n",
    "#     'l2_leaf_reg': [1, 3, 5],\n",
    "#     'bagging_temperature': [0, 0.5, 1]\n",
    "# }\n",
    "# catboost_grid = GridSearchCV(\n",
    "#     estimator=catboost,\n",
    "#     param_grid=catboost_param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# catboost_grid.fit(X_train, y_train)\n",
    "# best_catboost = catboost_grid.best_estimator_\n",
    "# print(\"Best CatBoost Parameters:\", catboost_grid.best_params_)\n",
    "\n",
    "# # Hyperparameter Tuning for XGBoost\n",
    "# xgboost = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "# xgboost_param_grid = {\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'n_estimators': [100, 200, 500],\n",
    "#     'subsample': [0.8, 1.0],\n",
    "#     'colsample_bytree': [0.8, 1.0]\n",
    "# }\n",
    "# xgboost_grid = GridSearchCV(\n",
    "#     estimator=xgboost,\n",
    "#     param_grid=xgboost_param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# xgboost_grid.fit(X_train, y_train)\n",
    "# best_xgboost = xgboost_grid.best_estimator_\n",
    "# print(\"Best XGBoost Parameters:\", xgboost_grid.best_params_)\n",
    "\n",
    "# # Hyperparameter Tuning for LightGBM\n",
    "# lightgbm = LGBMClassifier(random_state=42)\n",
    "# lightgbm_param_grid = {\n",
    "#     'num_leaves': [31, 50, 70],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'n_estimators': [100, 200, 500],\n",
    "#     'subsample': [0.8, 1.0],\n",
    "#     'colsample_bytree': [0.8, 1.0]\n",
    "# }\n",
    "# lightgbm_grid = GridSearchCV(\n",
    "#     estimator=lightgbm,\n",
    "#     param_grid=lightgbm_param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='accuracy',\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# lightgbm_grid.fit(X_train, y_train)\n",
    "# best_lightgbm = lightgbm_grid.best_estimator_\n",
    "# print(\"Best LightGBM Parameters:\", lightgbm_grid.best_params_)\n",
    "\n",
    "# # Ensemble: Voting Classifier\n",
    "# voting_clf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('catboost', best_catboost),\n",
    "#         ('xgboost', best_xgboost),\n",
    "#         ('lightgbm', best_lightgbm)\n",
    "#     ],\n",
    "#     voting='soft'\n",
    "# )\n",
    "# voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate All Models\n",
    "# models = {\n",
    "#     'CatBoost': best_catboost,\n",
    "#     'XGBoost': best_xgboost,\n",
    "#     'LightGBM': best_lightgbm,\n",
    "#     'Voting Classifier': voting_clf\n",
    "# }\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     print(f\"\\n{name} Evaluation:\")\n",
    "#     print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ad44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
